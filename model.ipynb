{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b42352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf27634",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b43c9",
   "metadata": {},
   "source": [
    "ADDERALL USE:\n",
    "Legally = 0\n",
    "Extralegally = 1\n",
    "\n",
    "RESULTS:\n",
    "No problems = 0\n",
    "Tolerance = 1\n",
    "Minor addiction = 2\n",
    "\n",
    "USE PATTERN:\n",
    "Less than once a month = 0\n",
    "Once a month - once a week = 1\n",
    "Once a week -  once a day = 2\n",
    "Daily or even more = 3\n",
    "\n",
    "ADDERALL DOSE\n",
    "10 mg or less = 0\n",
    "11 - 20 mg = 1\n",
    "21 - 40 mg = 2\n",
    "41 - 60 mg = 3\n",
    "61 - 100 mg = 4\n",
    "More than 100 mg = 5\n",
    "\n",
    "PHENIBUT DOSE\n",
    "500 mg or less = 0\n",
    "501 mg - 1 g = 1\n",
    "1g - 2g = 2\n",
    "2g - 5g = 3\n",
    "5g - 10g = 4\n",
    "Greater than 10g = 5\n",
    "\n",
    "NICOTINE USE\n",
    "I use/d nicotine less than once a week\n",
    "I use/d nicotine more than three times a day\n",
    "I use/d nicotine twice or three times a day\n",
    "I use/d nicotine daily\n",
    "2 = Between once a week and once a day\n",
    "\n",
    "MENTAL HEALTH\n",
    "I have no issues with anxiety = 0\n",
    "I have not been diagnosed, but I believe I have a problem with anxiety = 1\n",
    "I have a professionally diagnosed anxiety disorder = 2\n",
    "\n",
    "TYPE OF NICOTINE\n",
    "Normal tobacco cigarettes = 0\n",
    "Gum = 1\n",
    "Lozenges = 2\n",
    "E-cigarettes = 3\n",
    "Snus = 4\n",
    "\n",
    "The question are here https://docs.google.com/forms/d/e/1FAIpQLSfEek78AYqx5j61EzRX5M6Jy_3fX3xAz4f6gTFtPSEEtkwXug/viewform (the nootropics ratings go from 0 (\"worse\") to 10 (\"better\")\n",
    "\n",
    "Important:\n",
    "\n",
    "\"For each substance, please rate your subjective experience on a scale of 0 to 10. 0 means a substance was totally useless, or had so many side effects you couldn't continue taking it. 1 - 4 means for subtle effects, maybe placebo but still useful. 5 - 9 means strong effects, definitely not placebo. 10 means life-changing. Please as far as possible rate each substance on its own merits - but if a substance only works when stacked with another substance and you're not sure what to do, mention that in the comments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8e78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False #speedup autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4251e",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b19684",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc_df = pd.read_csv(\"fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b7391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all columns which are not nootropics ratings\n",
    "person_features_columns = ssc_df.columns[0:6]\n",
    "\n",
    "side_effects_columns = [\"SideEffectsofLSDMicrodosingverysmalldosewithouthallucinogeniceff\",\n",
    "                           \"SideEffectsofAdderall\",\n",
    "                           \"HowwereyouusingAdderall\",\n",
    "                           \"PatternofAdderallUse\",\n",
    "                           \"DoseofAdderallhighestdoseyouusedconsistentlyifyoutookmorethanonc\",\n",
    "                           \"ResultsofAdderalluse\",\n",
    "                           \"SideEffectsofPhenibut\",\n",
    "                           \"PatternofPhenibutUse\",\n",
    "                           \"Doseofphenibuthighestdoseyouusedconsistentlyifyoutookmorethanonc\",\n",
    "                           \"ResultsofPhenibutuse\"]\n",
    "\n",
    "other_features = ssc_df.columns[52:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e64197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display, HTML\n",
    "#display(HTML(ssc_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1e0fa",
   "metadata": {},
   "source": [
    "# Using Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2545952",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "- how to take into account external features (sex, age, anxiety) ? (different variance and mean etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09072139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = ssc_df.drop(columns = list(person_features_columns) + list(side_effects_columns) + list(other_features))\n",
    "#transform into a 3 columns (user_id, item_id, rating) matrix for Surprise\n",
    "df_clean = df_clean.rename_axis('userID').reset_index()\n",
    "df_clean = df_clean.melt(id_vars = \"userID\", var_name = \"itemID\", value_name = \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297972e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = ssc_df.drop(columns = list(person_features_columns) + list(side_effects_columns) + list(other_features))\n",
    "#transform into a 3 columns (user_id, item_id, rating) matrix for Surprise\n",
    "df_clean = df_clean.rename_axis('userID').reset_index()\n",
    "df_clean = df_clean.melt(id_vars = \"userID\", var_name = \"itemID\", value_name = \"rating\")\n",
    "#remove rows when there is no rating\n",
    "df_clean = df_clean[df_clean[\"rating\"] != \" \"]\n",
    "df_clean = df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45eb79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "# change the item names to id for Surprise\n",
    "#LE = LabelEncoder()\n",
    "#df_clean['itemID'] = LE.fit_transform(df_clean['itemID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce14c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = cross_validate(SVD(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0c76a",
   "metadata": {},
   "source": [
    "# Some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ad8cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      userID     itemID rating\n0          2  Modafinil      5\n1          3  Modafinil      9\n2          6  Modafinil      4\n3          7  Modafinil      5\n4          8  Modafinil      3\n...      ...        ...    ...\n6754     822   Nicotine      9\n6755     823   Nicotine      5\n6756     824   Nicotine      7\n6757     825   Nicotine     10\n6758     826   Nicotine      6\n\n[6759 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>itemID</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Modafinil</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Modafinil</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>Modafinil</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>Modafinil</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>Modafinil</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6754</th>\n      <td>822</td>\n      <td>Nicotine</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6755</th>\n      <td>823</td>\n      <td>Nicotine</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6756</th>\n      <td>824</td>\n      <td>Nicotine</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>6757</th>\n      <td>825</td>\n      <td>Nicotine</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6758</th>\n      <td>826</td>\n      <td>Nicotine</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>6759 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c71dda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848 users answered, and gave 6759 ratings\n",
      "with a mean of 7.970518867924528 ratings per user\n"
     ]
    }
   ],
   "source": [
    "print(\"{} users answered, and gave {} ratings\".format(len(ssc_df), len(df_clean)))\n",
    "print(\"with a mean of {} ratings per user\".format(len(df_clean) / len(ssc_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caceae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_users = df_clean.groupby(\"userID\").count()[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e754ad72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "6759"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_per_users.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b5d201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATlElEQVR4nO3df4xlZX3H8fe3i7WUMYCCk+2CXWmQBHbstjuhf9iQO/UXFVPEVMuGGLZaBxJobLp/uFpTqIaEWFfbxGqzFgJWZSAiSkFbCWGKJqW6Y5BZRBRwa3fZ7JYfLo4SmoFv/5gz9e54786d+2PvPQ/vVzKZe59z7jmfOZn97JnnnjkTmYkkqSy/MuwAkqT+s9wlqUCWuyQVyHKXpAJZ7pJUoOOGHQDglFNOyY0bN7Zc9rOf/YwTTjjh2AbqUp2yQr3y1ikr1CtvnbJCvfIOOuvc3NwTmXlqy4WZOfSPLVu2ZDv33HNP22Wjpk5ZM+uVt05ZM+uVt05ZM+uVd9BZgd3ZpledlpGkAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAKtevuBiLgeeCtwKDM3VWM3A2dVq5wE/CQzN0fERuAh4OFq2X2ZeXm/Q/fTxh13dv3avdde0MckktQ/ndxb5gbgk8Bnlwcy80+WH0fETuBw0/qPZubmPuWTJHVh1XLPzHurM/JfEhEBvBP4gz7nkiT1ILKDv6Falfsdy9MyTePnAR/PzMmm9R4EfgA8A3woM7/RZpvTwDTA+Pj4lpmZmZb7XlhYYGxsrMMvZ+3m9x9efaU2JjaceMTzQWfttzrlrVNWqFfeOmWFeuUddNapqam55f5dqddb/m4Fbmp6fgB4VWY+GRFbgC9HxDmZ+czKF2bmLmAXwOTkZDYajZY7mJ2dpd2yftjWy5z7JY0jng86a7/VKW+dskK98tYpK9Qr7zCzdn21TEQcB7wduHl5LDOfy8wnq8dzwKPAa3oNKUlam14uhXwD8P3M3Lc8EBGnRsS66vEZwJnAY71FlCSt1arlHhE3Af8BnBUR+yLiPdWiizlySgbgPOCBiPgu8EXg8sx8qp+BJUmr6+Rqma1txre1GLsVuLX3WJKkXvgbqpJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKtCq5R4R10fEoYjY0zR2dUTsj4j7q4+3NC37QEQ8EhEPR8SbBxVcktReJ2fuNwDntxj/RGZurj6+ChARZwMXA+dUr/lURKzrV1hJUmdWLffMvBd4qsPtXQjMZOZzmfkj4BHg3B7ySZK6EJm5+koRG4E7MnNT9fxqYBvwDLAb2J6ZT0fEJ4H7MvNz1XrXAV/LzC+22OY0MA0wPj6+ZWZmpuW+FxYWGBsbW/MX1qn5/Ye7fu3EhhOPeD7orP1Wp7x1ygr1ylunrFCvvIPOOjU1NZeZk62WHdflNj8NfATI6vNO4N1AtFi35f8embkL2AUwOTmZjUaj5Y5mZ2dpt6wftu24s+vX7r2kccTzQWfttzrlrVNWqFfeOmWFeuUdZtaurpbJzIOZ+XxmvgB8hl9MvewDTm9a9TTg8d4iSpLWqqtyj4j1TU8vApavpLkduDgiXhoRrwbOBL7VW0RJ0lqtOi0TETcBDeCUiNgHXAU0ImIzS1Mue4HLADLzwYi4BfgesAhckZnPDyS5JKmtVcs9M7e2GL7uKOtfA1zTSyhJUm/8DVVJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSpQt3eFFLBxxR0lt08sdnyXyb3XXjCISJIEeOYuSUWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCrlntEXB8RhyJiT9PY30bE9yPigYi4LSJOqsY3RsSzEXF/9fGPA8wuSWqjkzP3G4DzV4zdBWzKzNcCPwA+0LTs0czcXH1c3p+YkqS1WLXcM/Ne4KkVY1/PzMXq6X3AaQPIJknqUmTm6itFbATuyMxNLZb9C3BzZn6uWu9Bls7mnwE+lJnfaLPNaWAaYHx8fMvMzEzLfS8sLDA2NtbRF9ON+f2H+7at8ePh4LOdrTux4cS+7bdbgz62/VSnrFCvvHXKCvXKO+isU1NTc5k52WpZT7f8jYi/AhaBz1dDB4BXZeaTEbEF+HJEnJOZz6x8bWbuAnYBTE5OZqPRaLmP2dlZ2i3rh05v0duJ7ROL7Jzv7JDuvaTRt/12a9DHtp/qlBXqlbdOWaFeeYeZteurZSLiUuCtwCVZnf5n5nOZ+WT1eA54FHhNP4JKkjrXVblHxPnA+4E/ysyfN42fGhHrqsdnAGcCj/UjqCSpc6vOIUTETUADOCUi9gFXsXR1zEuBuyIC4L7qypjzgA9HxCLwPHB5Zj7VcsOSpIFZtdwzc2uL4evarHsrcGuvoSRJvfE3VCWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkFstwlqUCWuyQVyHKXpAJZ7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCrfo3VOtg4447hx1BkkbKqmfuEXF9RByKiD1NYy+PiLsi4ofV55Obln0gIh6JiIcj4s2DCi5Jaq+TaZkbgPNXjO0A7s7MM4G7q+dExNnAxcA51Ws+FRHr+pZWktSRVcs9M+8FnloxfCFwY/X4RuBtTeMzmflcZv4IeAQ4tz9RJUmdisxcfaWIjcAdmbmpev6TzDypafnTmXlyRHwSuC8zP1eNXwd8LTO/2GKb08A0wPj4+JaZmZmW+15YWGBsbOyo+eb3H171azgWxo+Hg892tu7EhhMHG6YDnRzbUVGnrFCvvHXKCvXKO+isU1NTc5k52WpZv99QjRZjLf/3yMxdwC6AycnJbDQaLTc4OztLu2XLto3IG6rbJxbZOd/ZId17SWOwYTrQybEdFXXKCvXKW6esUK+8w8za7aWQByNiPUD1+VA1vg84vWm904DHu48nSepGt+V+O3Bp9fhS4CtN4xdHxEsj4tXAmcC3eosoSVqrVecQIuImoAGcEhH7gKuAa4FbIuI9wI+BdwBk5oMRcQvwPWARuCIznx9QdklSG6uWe2ZubbPo9W3Wvwa4ppdQkqTeePsBSSqQ5S5JBbLcJalAlrskFaiIu0K+2PR6F8y9117QpySSRpVn7pJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBWo6/u5R8RZwM1NQ2cAfw2cBLwX+J9q/IOZ+dVu9yNJWruuyz0zHwY2A0TEOmA/cBvwp8AnMvNj/QgoSVq7fk3LvB54NDP/q0/bkyT1oF/lfjFwU9PzKyPigYi4PiJO7tM+JEkdiszsbQMRvwo8DpyTmQcjYhx4AkjgI8D6zHx3i9dNA9MA4+PjW2ZmZlpuf2FhgbGxsaNmmN9/uKevoV/Gj4eDz3a27sSGE7veT69f7/K+Ozm2o6JOWaFeeeuUFeqVd9BZp6am5jJzstWyfpT7hcAVmfmmFss2Andk5qajbWNycjJ3797dctns7CyNRuOoGXr9g9H9sn1ikZ3znb2N0csfqe7XH8ju5NiOijplhXrlrVNWqFfeQWeNiLbl3o9pma00TclExPqmZRcBe/qwD0nSGnR9tQxARPw68Ebgsqbhj0bEZpamZfauWCZJOgZ6KvfM/DnwihVj7+opkSSpZ/6GqiQVyHKXpAL1NC2jelq+2mb7xCLb1njlTS9X+Ug6djxzl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAvkbqkMyKvegl1Qmz9wlqUCWuyQVyHKXpAJZ7pJUIMtdkgrk1TJak16u8vFe8NKx45m7JBWopzP3iNgL/BR4HljMzMmIeDlwM7AR2Au8MzOf7i2mJGkt+nHmPpWZmzNzsnq+A7g7M88E7q6eS5KOoUFMy1wI3Fg9vhF42wD2IUk6il7LPYGvR8RcRExXY+OZeQCg+vzKHvchSVqjyMzuXxzxG5n5eES8ErgL+HPg9sw8qWmdpzPz5BavnQamAcbHx7fMzMy03MfCwgJjY2NHzTG//3DXX0M/jR8PB58ddorOHeu8ExtO7Pq1nXwfjJI65a1TVqhX3kFnnZqammuaEj9CT+V+xIYirgYWgPcCjcw8EBHrgdnMPOtor52cnMzdu3e3XDY7O0uj0TjqvkflJlzbJxbZOV+fq0uPdd5eLoXs5PtglNQpb52yQr3yDjprRLQt966nZSLihIh42fJj4E3AHuB24NJqtUuBr3S7D0lSd3o5bRsHbouI5e18ITP/NSK+DdwSEe8Bfgy8o/eYkqS16LrcM/Mx4LdbjD8JvL6XUJKk3vgbqpJUIMtdkgpkuUtSgSx3SSqQ5S5JBbLcJalAlrskFchyl6QCWe6SVCDLXZIKZLlLUoEsd0kqkOUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCmS5S1KBLHdJKpDlLkkF6rrcI+L0iLgnIh6KiAcj4n3V+NURsT8i7q8+3tK/uJKkThzXw2sXge2Z+Z2IeBkwFxF3Vcs+kZkf6z2eJKkbXZd7Zh4ADlSPfxoRDwEb+hVMktS9yMzeNxKxEbgX2AT8JbANeAbYzdLZ/dMtXjMNTAOMj49vmZmZabnthYUFxsbGjrr/+f2Huw/fR+PHw8Fnh52ic8c678SGE7t+bSffB6OkTnnrlBXqlXfQWaempuYyc7LVsp7LPSLGgH8HrsnML0XEOPAEkMBHgPWZ+e6jbWNycjJ3797dctns7CyNRuOoGTbuuLOL5P23fWKRnfO9zHQdW8c6795rL+j6tZ18H4ySOuWtU1aoV95BZ42ItuXe09UyEfES4Fbg85n5JYDMPJiZz2fmC8BngHN72Yckae26Pm2LiACuAx7KzI83ja+v5uMBLgL29BZR6l0vP9318hOHNCy9/Ez+OuBdwHxE3F+NfRDYGhGbWZqW2Qtc1sM+JEld6OVqmW8C0WLRV7uPI0nqh/q8+6cXtfn9h9k2Im+cS3Xg7QckqUCeueuY6eVNze0TfQwivQh45i5JBbLcJalAlrskFchyl6QCWe6SVCCvlpFW0c1VPtsnFtm2405vXaCh8cxdkgrkmbs0QMO6Ydla9rv8U0a/9q3RYLlLI2pU/k6B6slpGUkqkGfuktSjdj9ltZryWmlQU2CeuUtSgSx3SSqQ0zKSfol/lrD+PHOXpAJ55i7pRa/Ey049c5ekAg3szD0izgf+HlgH/FNmXjuofUkqQydn0O0uL3Su/0gDOXOPiHXAPwB/CJwNbI2IswexL0nSLxvUmfu5wCOZ+RhARMwAFwLfG9D+JL3IlThv3ovIzP5vNOKPgfMz88+q5+8Cfi8zr2xaZxqYrp6eBTzcZnOnAE/0PeRg1Ckr1CtvnbJCvfLWKSvUK++gs/5mZp7aasGgztyjxdgR/4tk5i5g16obitidmZP9CjZIdcoK9cpbp6xQr7x1ygr1yjvMrIO6WmYfcHrT89OAxwe0L0nSCoMq928DZ0bEqyPiV4GLgdsHtC9J0goDmZbJzMWIuBL4N5Yuhbw+Mx/scnOrTt2MkDplhXrlrVNWqFfeOmWFeuUdWtaBvKEqSRouf0NVkgpkuUtSgUa23CPi/Ih4OCIeiYgdw86zmojYGxHzEXF/ROwedp6VIuL6iDgUEXuaxl4eEXdFxA+rzycPM+OyNlmvjoj91fG9PyLeMsyMyyLi9Ii4JyIeiogHI+J91fioHtt2eUfu+EbEr0XEtyLiu1XWv6nGR/XYtss7lGM7knPu1e0LfgC8kaXLKr8NbM3Mkf0N14jYC0xm5kj+ckVEnAcsAJ/NzE3V2EeBpzLz2uo/0JMz8/3DzFnlapX1amAhMz82zGwrRcR6YH1mficiXgbMAW8DtjGax7Zd3ncyYsc3IgI4ITMXIuIlwDeB9wFvZzSPbbu85zOEYzuqZ+7/f/uCzPxfYPn2BepSZt4LPLVi+ELgxurxjSz9Ix+6NllHUmYeyMzvVI9/CjwEbGB0j227vCMnlyxUT19SfSSje2zb5R2KUS33DcB/Nz3fx4h+AzZJ4OsRMVfdWqEOxjPzACz9owdeOeQ8q7kyIh6opm1G4kfxZhGxEfgd4D+pwbFdkRdG8PhGxLqIuB84BNyVmSN9bNvkhSEc21Et91VvXzCCXpeZv8vSnTCvqKYW1D+fBn4L2AwcAHYONc0KETEG3Ar8RWY+M+w8q2mRdySPb2Y+n5mbWfot93MjYtOQIx1Vm7xDObajWu61u31BZj5efT4E3MbS1NKoO1jNwS7PxR4acp62MvNg9Q/nBeAzjNDxreZXbwU+n5lfqoZH9ti2yjvKxxcgM38CzLI0fz2yx3ZZc95hHdtRLfda3b4gIk6o3pwiIk4A3gTsOfqrRsLtwKXV40uBrwwxy1Et/2OuXMSIHN/qTbTrgIcy8+NNi0by2LbLO4rHNyJOjYiTqsfHA28Avs/oHtuWeYd1bEfyahmA6nKhv+MXty+4ZriJ2ouIM1g6W4elWzp8YdTyRsRNQIOlW5AeBK4CvgzcArwK+DHwjswc+huZbbI2WPqxNoG9wGXL867DFBG/D3wDmAdeqIY/yNI89ige23Z5tzJixzciXsvSG6brWDoRvSUzPxwRr2A0j227vP/MEI7tyJa7JKl7ozotI0nqgeUuSQWy3CWpQJa7JBXIcpekAlnuklQgy12SCvR/7+usXx9CDSAAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings_per_users.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0817a9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(sum(ratings_per_users == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802758d",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15cae9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor, SVD, NMF, SlopeOne, CoClustering, KNNBasic, KNNWithZScore, KNNWithMeans, KNNBaseline, SVDpp\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf75b3",
   "metadata": {},
   "source": [
    "## Algorithm selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcada0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df_clean, reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7169a5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SlopeOne\n",
      "Evaluating RMSE, MAE, FCP of algorithm SlopeOne on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3862  2.3414  2.4091  2.3931  2.3466  2.3753  0.0267  \n",
      "MAE (testset)     1.8626  1.8374  1.8707  1.8849  1.8114  1.8534  0.0261  \n",
      "FCP (testset)     0.5658  0.5810  0.5394  0.5659  0.5885  0.5681  0.0168  \n",
      "Fit time          0.03    0.03    0.04    0.03    0.06    0.04    0.01    \n",
      "Test time         0.04    0.05    0.05    0.04    0.05    0.05    0.01    \n",
      "{'test_rmse': array([2.386214  , 2.34143354, 2.40912565, 2.39314993, 2.34655703]), 'test_mae': array([1.86256892, 1.83744768, 1.87069939, 1.8849496 , 1.81135416]), 'test_fcp': array([0.56579585, 0.58102634, 0.53943333, 0.56594365, 0.58849984]), 'fit_time': (0.02635502815246582, 0.031139135360717773, 0.03924822807312012, 0.031210899353027344, 0.05977511405944824), 'test_time': (0.039418697357177734, 0.0461421012878418, 0.05343198776245117, 0.03727388381958008, 0.0517730712890625)}\n",
      "CoClustering\n",
      "Evaluating RMSE, MAE, FCP of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.4371  2.5727  2.5252  2.5766  2.5018  2.5227  0.0513  \n",
      "MAE (testset)     1.9169  2.0256  1.9713  1.9951  1.9632  1.9744  0.0361  \n",
      "FCP (testset)     0.5471  0.5619  0.5826  0.5448  0.5414  0.5556  0.0152  \n",
      "Fit time          0.47    0.41    0.34    0.41    0.53    0.43    0.06    \n",
      "Test time         0.01    0.01    0.02    0.02    0.02    0.02    0.00    \n",
      "SVD\n",
      "Evaluating RMSE, MAE, FCP of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3392  2.3279  2.3249  2.3043  2.3442  2.3281  0.0139  \n",
      "MAE (testset)     1.8891  1.8386  1.8228  1.8539  1.8637  1.8536  0.0225  \n",
      "FCP (testset)     0.5982  0.5808  0.5407  0.5329  0.5629  0.5631  0.0243  \n",
      "Fit time          0.66    0.90    0.70    0.65    0.66    0.71    0.09    \n",
      "Test time         0.02    0.03    0.02    0.02    0.02    0.02    0.00    \n",
      "SVDpp\n",
      "Evaluating RMSE, MAE, FCP of algorithm SVDpp on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3468  2.3560  2.4643  2.3745  2.4433  2.3970  0.0477  \n",
      "MAE (testset)     1.8542  1.8427  1.9228  1.8476  1.9116  1.8758  0.0342  \n",
      "FCP (testset)     0.5513  0.5819  0.5505  0.5405  0.5369  0.5522  0.0159  \n",
      "Fit time          2.64    3.23    3.52    3.74    3.33    3.29    0.37    \n",
      "Test time         0.26    0.09    0.10    0.08    0.08    0.12    0.07    \n",
      "KNN... (user based)\n",
      "with means\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3939  2.4309  2.4203  2.4018  2.4026  2.4099  0.0136  \n",
      "MAE (testset)     1.8841  1.9163  1.9357  1.8851  1.9011  1.9045  0.0196  \n",
      "FCP (testset)     0.5583  0.5548  0.5712  0.5478  0.5507  0.5566  0.0081  \n",
      "Fit time          0.19    0.15    0.13    0.15    0.15    0.15    0.02    \n",
      "Test time         0.89    0.84    0.94    0.89    1.02    0.92    0.06    \n",
      "with z-score\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.4261  2.4024  2.4671  2.4497  2.4581  2.4407  0.0235  \n",
      "MAE (testset)     1.8985  1.8825  1.9482  1.8927  1.9459  1.9136  0.0278  \n",
      "FCP (testset)     0.5565  0.5437  0.5357  0.5497  0.5481  0.5467  0.0069  \n",
      "Fit time          0.22    0.25    0.24    0.57    0.34    0.32    0.13    \n",
      "Test time         1.22    0.93    1.43    1.70    1.17    1.29    0.26    \n",
      "with baselines\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3057  2.2967  2.2889  2.3765  2.3433  2.3222  0.0329  \n",
      "MAE (testset)     1.8119  1.8145  1.8458  1.8759  1.8631  1.8422  0.0256  \n",
      "FCP (testset)     0.5957  0.5674  0.5453  0.5585  0.5770  0.5687  0.0170  \n",
      "Fit time          0.12    0.14    0.11    0.11    0.12    0.12    0.01    \n",
      "Test time         0.89    0.85    0.77    0.97    0.83    0.86    0.07    \n",
      "KNN... (item based)\n",
      "with means\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3816  2.3971  2.4106  2.4279  2.3103  2.3855  0.0406  \n",
      "MAE (testset)     1.8671  1.8874  1.8708  1.8841  1.8032  1.8625  0.0307  \n",
      "FCP (testset)     0.5656  0.5439  0.5871  0.5775  0.5735  0.5695  0.0145  \n",
      "Fit time          0.01    0.03    0.01    0.01    0.01    0.01    0.01    \n",
      "Test time         0.07    0.08    0.07    0.06    0.07    0.07    0.01    \n",
      "with z-scores\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNWithZScore on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3958  2.3381  2.3516  2.3202  2.4029  2.3617  0.0324  \n",
      "MAE (testset)     1.8703  1.8154  1.8557  1.8120  1.8584  1.8423  0.0239  \n",
      "FCP (testset)     0.5763  0.5728  0.5338  0.5869  0.5846  0.5709  0.0192  \n",
      "Fit time          0.01    0.01    0.02    0.02    0.02    0.02    0.00    \n",
      "Test time         0.06    0.07    0.08    0.07    0.12    0.08    0.02    \n",
      "with baselines\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE, FCP of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    2.3519  2.3128  2.3746  2.4029  2.4651  2.3815  0.0512  \n",
      "MAE (testset)     1.8278  1.7916  1.8550  1.8419  1.9281  1.8489  0.0449  \n",
      "FCP (testset)     0.5929  0.5916  0.5792  0.5669  0.5497  0.5761  0.0162  \n",
      "Fit time          0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Test time         0.10    0.10    0.09    0.08    0.10    0.09    0.01    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "algorithms = [\"SlopeOne\", \n",
    "              \"CoClustering\", \n",
    "              \"SVD\", \n",
    "              \"SVDpp\",\n",
    "              \"KNN_means_users\", \n",
    "              \"KNN_zscore_users\", \n",
    "              \"KNN_baselines_users\",\n",
    "              \"KNN_means_items\", \n",
    "              \"KNN_zscore_items\", \n",
    "              \"KNN_baselines_items\"]\n",
    "rmse = []\n",
    "mae = []\n",
    "fcp = []\n",
    "print(\"SlopeOne\")\n",
    "res = cross_validate(SlopeOne(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "print(res)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"CoClustering\")\n",
    "res = cross_validate(CoClustering(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"SVD\")\n",
    "res = cross_validate(SVD(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"SVDpp\")\n",
    "res = cross_validate(SVDpp(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"KNN... (user based)\")\n",
    "print(\"with means\")\n",
    "res = cross_validate(KNNWithMeans(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"with z-score\")\n",
    "res = cross_validate(KNNWithZScore(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"with baselines\")\n",
    "res = cross_validate(KNNBaseline(), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"KNN... (item based)\")\n",
    "print(\"with means\")\n",
    "res = cross_validate(KNNWithMeans(sim_options = {'user_based': False}), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"with z-scores\")\n",
    "res = cross_validate(KNNWithZScore(sim_options = {'user_based': False}), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))\n",
    "print(\"with baselines\")\n",
    "res = cross_validate(KNNBaseline(sim_options = {'user_based': False}), data, cv=5, measures = [\"rmse\", \"mae\", \"fcp\"], verbose=True)\n",
    "rmse.append(np.mean(res[\"test_rmse\"]))\n",
    "mae.append(np.mean(res[\"test_mae\"]))\n",
    "fcp.append(np.mean(res[\"test_fcp\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bcc98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                  algo      rmse       mae       fcp\n0             SlopeOne  2.375296  1.853404  0.568140\n1         CoClustering  2.522691  1.974431  0.555576\n2                  SVD  2.328078  1.853617  0.563088\n3                SVDpp  2.396982  1.875759  0.552250\n4      KNN_means_users  2.409913  1.904471  0.556563\n5     KNN_zscore_users  2.440679  1.913571  0.546748\n6  KNN_baselines_users  2.322214  1.842249  0.568748\n7      KNN_means_items  2.385486  1.862518  0.569515\n8     KNN_zscore_items  2.361710  1.842346  0.570890\n9  KNN_baselines_items  2.381464  1.848874  0.576054",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>algo</th>\n      <th>rmse</th>\n      <th>mae</th>\n      <th>fcp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SlopeOne</td>\n      <td>2.375296</td>\n      <td>1.853404</td>\n      <td>0.568140</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CoClustering</td>\n      <td>2.522691</td>\n      <td>1.974431</td>\n      <td>0.555576</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVD</td>\n      <td>2.328078</td>\n      <td>1.853617</td>\n      <td>0.563088</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SVDpp</td>\n      <td>2.396982</td>\n      <td>1.875759</td>\n      <td>0.552250</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KNN_means_users</td>\n      <td>2.409913</td>\n      <td>1.904471</td>\n      <td>0.556563</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNN_zscore_users</td>\n      <td>2.440679</td>\n      <td>1.913571</td>\n      <td>0.546748</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KNN_baselines_users</td>\n      <td>2.322214</td>\n      <td>1.842249</td>\n      <td>0.568748</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KNN_means_items</td>\n      <td>2.385486</td>\n      <td>1.862518</td>\n      <td>0.569515</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KNN_zscore_items</td>\n      <td>2.361710</td>\n      <td>1.842346</td>\n      <td>0.570890</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>KNN_baselines_items</td>\n      <td>2.381464</td>\n      <td>1.848874</td>\n      <td>0.576054</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame({\"algo\":algorithms, \"rmse\":rmse, \"mae\":mae, \"fcp\":fcp})\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049db29",
   "metadata": {},
   "source": [
    "The two best ones seem to be SVD and KNN_baselines_users (they seem to be equivalent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f06acd",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7f7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_params_dic = {\"n_factors\":[10, 50, 100, 300], \"n_epochs\":[20, 40, 100], \"lr_all\":[0.005, 0.1], \"reg_all\":[0.02, 0.1, 0.002]}\n",
    "\n",
    "param_search = RandomizedSearchCV(SVD, svd_params_dic)\n",
    "param_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91978a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.1}, 'mae': {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.1}}\n",
      "{'rmse': 2.3082569695050035, 'mae': 1.8374777419852948}\n"
     ]
    }
   ],
   "source": [
    "print(param_search.best_params)\n",
    "print(param_search.best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967fc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo/opt/anaconda3/envs/nootropics/lib/python3.8/site-packages/surprise/prediction_algorithms/algo_base.py:249: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim = construction_func[name](*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "knn_params_dic = {\"k\":[10, 20, 40, 60, 100], \n",
    "                  \"min_k\":[1, 2, 5, 10],\n",
    "                  \"sim_options\":{'name': ['pearson_baseline', 'msd', 'cosine'], \"user_based\":[True]}}\n",
    "\n",
    "knn_param_search = RandomizedSearchCV(KNNBaseline, knn_params_dic);\n",
    "knn_param_search.fit(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a64434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'k': 60, 'min_k': 2, 'sim_options': {'name': 'pearson_baseline', 'user_based': True}}, 'mae': {'k': 60, 'min_k': 2, 'sim_options': {'name': 'pearson_baseline', 'user_based': True}}}\n",
      "{'rmse': 2.3081040522732574, 'mae': 1.8321081214813546}\n"
     ]
    }
   ],
   "source": [
    "print(knn_param_search.best_params)\n",
    "print(knn_param_search.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b1b88",
   "metadata": {},
   "source": [
    "## The best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e04475cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7ffbb5dab6d0>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = KNNBaseline(k=60, min_k=2, sim_options={'name': 'pearson_baseline', 'user_based':True})\n",
    "#train on the whole dataset\n",
    "trainset = data.build_full_trainset()\n",
    "final_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2f96f",
   "metadata": {},
   "source": [
    "### TODO\n",
    "ensemble the two models ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1f10a",
   "metadata": {},
   "source": [
    "# Predictions for new users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109f5798",
   "metadata": {},
   "source": [
    "## Create a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e441ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings = {'Modafinil': 6, \n",
    "                    'Caffeine': 6,\n",
    "                    'Coluracetam': None, \n",
    "                    'Phenylpiracetam': None,\n",
    "                    'Theanine': 7,\n",
    "                    'Noopept': None,\n",
    "                    'Oxiracetam': None,\n",
    "                    'Aniracetam': None,\n",
    "                    'Rhodiola': None,\n",
    "                    'Creatine': 4,\n",
    "                    'Piracetam': None,\n",
    "                    'Ashwagandha': None,\n",
    "                    'Bacopa': None,\n",
    "                    'Choline': None,\n",
    "                    'DMAE': None,\n",
    "                    'Fasoracetam': None,\n",
    "                    'SemaxandNASemaxetc': None,\n",
    "                    'SelankandNASelanketc': None,\n",
    "                    'Inositol': None,\n",
    "                    'Seligiline': None,\n",
    "                    'AlphaBrainproprietaryblend': None,\n",
    "                    'Cerebrolysin': None,\n",
    "                    'Melatonin': 8,\n",
    "                    'Uridine': None,\n",
    "                    'Tianeptine': None,\n",
    "                    'MethyleneBlue': None,\n",
    "                    'Unifiram': None,\n",
    "                    'PRL853': None,\n",
    "                    'Emoxypine': None,\n",
    "                    'Picamilon': None,\n",
    "                    'Dihexa': None,\n",
    "                    'Epicorasimmunebooster': None,\n",
    "                    'LSD': 7,\n",
    "                    'Adderall': 8,\n",
    "                    \"Phenibut\": 6,\n",
    "                    \"Nicotine\": 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b001b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = max(df_clean[\"userID\"]) + 1\n",
    "ratings = np.array(list(new_user_ratings.values()))\n",
    "rated_mask = ratings != None\n",
    "ratings = ratings[rated_mask]\n",
    "items = np.array(list(new_user_ratings.keys()))[rated_mask]\n",
    "user = np.ones(len(items), dtype=\"int\") * new_user_id\n",
    "new_user_df = pd.DataFrame({\"userID\":user, \"itemID\":items, \"rating\":ratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0b52700",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = df_clean.append(new_user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a80fe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "new_trainset = Dataset.load_from_df(total_df, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d8fe5",
   "metadata": {},
   "source": [
    "## Fit the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c97ae2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7ffbb5dab6d0>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(new_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dd0a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nootropics = new_user_ratings.keys()\n",
    "predicted_ratings = []\n",
    "for nootropic in all_nootropics:\n",
    "    predicted_ratings.append(final_model.predict(new_user_id, nootropic).est)\n",
    "    \n",
    "item_baselines = final_model.default_prediction() + final_model.compute_baselines()[1] # mean rating + item baseline ?\n",
    "\n",
    "result_df = pd.DataFrame({\"nootropic\":all_nootropics, \"predicted_rating\":predicted_ratings, \"baseline_rating\":item_baselines})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c438b671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                     nootropic  predicted_rating  baseline_rating\n33                    Adderall          7.997645         7.681135\n22                   Melatonin          7.916746         5.689561\n35                    Nicotine          7.158815         5.772261\n4                     Theanine          7.121568         5.137373\n32                         LSD          7.107606         6.234681\n16          SemaxandNASemaxetc          6.960977         6.167291\n24                  Tianeptine          6.524165         6.434908\n1                     Caffeine          6.421540         6.018941\n21                Cerebrolysin          6.323260         5.615556\n34                    Phenibut          6.155112         7.029181\n0                    Modafinil          6.040632         6.631811\n17        SelankandNASelanketc          5.942025         5.672601\n27                      PRL853          5.881803         5.629883\n11                 Ashwagandha          5.603798         5.264983\n31       Epicorasimmunebooster          5.588897         5.505173\n25               MethyleneBlue          5.511611         4.978221\n5                      Noopept          5.480014         4.858149\n3              Phenylpiracetam          5.382007         5.346027\n23                     Uridine          5.224637         5.101100\n7                   Aniracetam          5.201553         4.955426\n26                    Unifiram          5.114960         4.828868\n10                   Piracetam          5.098493         4.661614\n6                   Oxiracetam          4.967779         5.057999\n12                      Bacopa          4.840842         4.790474\n8                     Rhodiola          4.650908         4.516702\n28                   Emoxypine          4.574101         4.678998\n2                  Coluracetam          4.561890         4.784907\n30                      Dihexa          4.508941         5.072679\n15                 Fasoracetam          4.409967         4.541294\n13                     Choline          4.354001         4.192473\n14                        DMAE          4.349459         4.439559\n9                     Creatine          4.282800         4.601508\n18                    Inositol          4.270743         4.087739\n19                  Seligiline          3.896780         5.097957\n29                   Picamilon          3.763101         3.868758\n20  AlphaBrainproprietaryblend          2.943112         3.521495",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nootropic</th>\n      <th>predicted_rating</th>\n      <th>baseline_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>Adderall</td>\n      <td>7.997645</td>\n      <td>7.681135</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Melatonin</td>\n      <td>7.916746</td>\n      <td>5.689561</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Nicotine</td>\n      <td>7.158815</td>\n      <td>5.772261</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Theanine</td>\n      <td>7.121568</td>\n      <td>5.137373</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>LSD</td>\n      <td>7.107606</td>\n      <td>6.234681</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SemaxandNASemaxetc</td>\n      <td>6.960977</td>\n      <td>6.167291</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Tianeptine</td>\n      <td>6.524165</td>\n      <td>6.434908</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Caffeine</td>\n      <td>6.421540</td>\n      <td>6.018941</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Cerebrolysin</td>\n      <td>6.323260</td>\n      <td>5.615556</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Phenibut</td>\n      <td>6.155112</td>\n      <td>7.029181</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Modafinil</td>\n      <td>6.040632</td>\n      <td>6.631811</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SelankandNASelanketc</td>\n      <td>5.942025</td>\n      <td>5.672601</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>PRL853</td>\n      <td>5.881803</td>\n      <td>5.629883</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Ashwagandha</td>\n      <td>5.603798</td>\n      <td>5.264983</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Epicorasimmunebooster</td>\n      <td>5.588897</td>\n      <td>5.505173</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>MethyleneBlue</td>\n      <td>5.511611</td>\n      <td>4.978221</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Noopept</td>\n      <td>5.480014</td>\n      <td>4.858149</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phenylpiracetam</td>\n      <td>5.382007</td>\n      <td>5.346027</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Uridine</td>\n      <td>5.224637</td>\n      <td>5.101100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Aniracetam</td>\n      <td>5.201553</td>\n      <td>4.955426</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Unifiram</td>\n      <td>5.114960</td>\n      <td>4.828868</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Piracetam</td>\n      <td>5.098493</td>\n      <td>4.661614</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Oxiracetam</td>\n      <td>4.967779</td>\n      <td>5.057999</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Bacopa</td>\n      <td>4.840842</td>\n      <td>4.790474</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Rhodiola</td>\n      <td>4.650908</td>\n      <td>4.516702</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Emoxypine</td>\n      <td>4.574101</td>\n      <td>4.678998</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coluracetam</td>\n      <td>4.561890</td>\n      <td>4.784907</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Dihexa</td>\n      <td>4.508941</td>\n      <td>5.072679</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Fasoracetam</td>\n      <td>4.409967</td>\n      <td>4.541294</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Choline</td>\n      <td>4.354001</td>\n      <td>4.192473</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>DMAE</td>\n      <td>4.349459</td>\n      <td>4.439559</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Creatine</td>\n      <td>4.282800</td>\n      <td>4.601508</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Inositol</td>\n      <td>4.270743</td>\n      <td>4.087739</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Seligiline</td>\n      <td>3.896780</td>\n      <td>5.097957</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Picamilon</td>\n      <td>3.763101</td>\n      <td>3.868758</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>AlphaBrainproprietaryblend</td>\n      <td>2.943112</td>\n      <td>3.521495</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(\"predicted_rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1b8d6",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Use user features (sex, age, self-rated anxiety, depression and ADHD...) (see https://github.com/NicolasHug/Surprise/pull/159 and  https://github.com/martincousi/Surprise/blob/sample_weight/surprise/prediction_algorithms/factorization_machines.py for a discussion on how to use this inside Surprise)\n",
    "- is Surprise good ? Can I get better results with RandomForest etc ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}